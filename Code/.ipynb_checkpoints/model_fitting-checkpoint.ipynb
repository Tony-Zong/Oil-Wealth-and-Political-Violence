{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058577f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import sklearn\n",
    "import os\n",
    "from matplotlib.pyplot import hist\n",
    "# import more functions or modules if you need them !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774f543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for numpy\n",
    "RANDOM_SEED=42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53433a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_df = pd.read_pickle('../Data/data/comprehensive_new_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97694e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>numcode</th>\n",
       "      <th>oilreserves_full</th>\n",
       "      <th>oilreserves</th>\n",
       "      <th>oilreserves_public</th>\n",
       "      <th>newdiscovery_aspo</th>\n",
       "      <th>aspo</th>\n",
       "      <th>wildcat</th>\n",
       "      <th>endowment</th>\n",
       "      <th>pop_maddison</th>\n",
       "      <th>...</th>\n",
       "      <th>valoilres_binarize</th>\n",
       "      <th>valoilres_public_diff</th>\n",
       "      <th>valoilres_public_binarize</th>\n",
       "      <th>oilpop_diff</th>\n",
       "      <th>oilpop_binarize</th>\n",
       "      <th>valoilres_impute_diff</th>\n",
       "      <th>valoilres_impute_binarize</th>\n",
       "      <th>oilpop_impute_diff</th>\n",
       "      <th>oilpop_impute_binarize</th>\n",
       "      <th>milexp_pergdpSIPRI_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1929.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1930.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1931.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1932.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1933.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17915</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>894</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10962.026367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17916</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>894</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>11115.380859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17917</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>894</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>11288.252930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17918</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>894</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>11477.447266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17919</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>894</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>11669.534180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17920 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  numcode  oilreserves_full  oilreserves  oilreserves_public  \\\n",
       "0      1929.0        4               NaN          NaN                 NaN   \n",
       "1      1930.0        4               NaN          NaN                 NaN   \n",
       "2      1931.0        4               NaN          NaN                 NaN   \n",
       "3      1932.0        4               NaN          NaN                 NaN   \n",
       "4      1933.0        4               NaN          NaN                 NaN   \n",
       "...       ...      ...               ...          ...                 ...   \n",
       "17915  2004.0      894           0.00001          NaN             0.00001   \n",
       "17916  2005.0      894           0.00001          NaN             0.00001   \n",
       "17917  2006.0      894           0.00001          NaN             0.00001   \n",
       "17918  2007.0      894           0.00001          NaN             0.00001   \n",
       "17919  2008.0      894           0.00001          NaN             0.00001   \n",
       "\n",
       "       newdiscovery_aspo  aspo  wildcat  endowment  pop_maddison  ...  \\\n",
       "0                    NaN   NaN      NaN        NaN           NaN  ...   \n",
       "1                    NaN   NaN      NaN        NaN           NaN  ...   \n",
       "2                    NaN   NaN      NaN        NaN           NaN  ...   \n",
       "3                    NaN   NaN      NaN        NaN           NaN  ...   \n",
       "4                    NaN   NaN      NaN        NaN           NaN  ...   \n",
       "...                  ...   ...      ...        ...           ...  ...   \n",
       "17915                NaN   NaN      NaN    0.00001  10962.026367  ...   \n",
       "17916                NaN   NaN      NaN    0.00001  11115.380859  ...   \n",
       "17917                NaN   NaN      NaN    0.00001  11288.252930  ...   \n",
       "17918                NaN   NaN      NaN    0.00001  11477.447266  ...   \n",
       "17919                NaN   NaN      NaN    0.00001  11669.534180  ...   \n",
       "\n",
       "       valoilres_binarize  valoilres_public_diff  valoilres_public_binarize  \\\n",
       "0                     NaN                    NaN                        NaN   \n",
       "1                     NaN                    NaN                        NaN   \n",
       "2                     NaN                    NaN                        NaN   \n",
       "3                     NaN                    NaN                        NaN   \n",
       "4                     NaN                    NaN                        NaN   \n",
       "...                   ...                    ...                        ...   \n",
       "17915                 0.0                    0.0                        0.0   \n",
       "17916                 0.0                    0.0                        0.0   \n",
       "17917                 0.0                    0.0                        0.0   \n",
       "17918                 0.0                    0.0                        0.0   \n",
       "17919                 0.0                    0.0                        0.0   \n",
       "\n",
       "       oilpop_diff  oilpop_binarize  valoilres_impute_diff  \\\n",
       "0              NaN              NaN                    NaN   \n",
       "1              NaN              NaN                    NaN   \n",
       "2              NaN              NaN                    NaN   \n",
       "3              NaN              NaN                    NaN   \n",
       "4              NaN              NaN                    NaN   \n",
       "...            ...              ...                    ...   \n",
       "17915          0.0              0.0                    0.0   \n",
       "17916          0.0              0.0                    0.0   \n",
       "17917          0.0              0.0                    0.0   \n",
       "17918          0.0              0.0                    0.0   \n",
       "17919          0.0              0.0                    0.0   \n",
       "\n",
       "       valoilres_impute_binarize  oilpop_impute_diff  oilpop_impute_binarize  \\\n",
       "0                            NaN                 NaN                     NaN   \n",
       "1                            NaN                 NaN                     NaN   \n",
       "2                            NaN                 NaN                     NaN   \n",
       "3                            NaN                 NaN                     NaN   \n",
       "4                            NaN                 NaN                     NaN   \n",
       "...                          ...                 ...                     ...   \n",
       "17915                        0.0                 0.0                     0.0   \n",
       "17916                        0.0                 0.0                     0.0   \n",
       "17917                        0.0                 0.0                     0.0   \n",
       "17918                        0.0                 0.0                     0.0   \n",
       "17919                        0.0                 0.0                     0.0   \n",
       "\n",
       "       milexp_pergdpSIPRI_diff  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "...                        ...  \n",
       "17915                      NaN  \n",
       "17916                      NaN  \n",
       "17917                      NaN  \n",
       "17918                      NaN  \n",
       "17919                      NaN  \n",
       "\n",
       "[17920 rows x 96 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oil_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22d6d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'numcode', 'oilreserves_full', 'oilreserves',\n",
       "       'oilreserves_public', 'newdiscovery_aspo', 'aspo', 'wildcat',\n",
       "       'endowment', 'pop_maddison', 'ecgrowth', 'efrac', 'lfrac', 'rfrac',\n",
       "       'incidence2COW', 'onset2COWCS', 'incidenceU', 'onsetUCS', 'Fearon_war',\n",
       "       'onset_FearonCS', 'Sambanis_war', 'onset_SambanisCS', 'coup',\n",
       "       'any_coup', 'periregular', 'no_transition', 'milexp_pergdpSIPRI',\n",
       "       'mountain', 'religion_fractionalization', 'ethnic_fractionalization',\n",
       "       'language_fractionalization', 'ETHPOL_reynal', 'ETHFRAC_reynal',\n",
       "       'RELPOL_reynal', 'RELFRAC_reynal', 'leg_british', 'rule_law96',\n",
       "       'land_area', 'crude1990P', 'smallregion', 'largeregion', 'code3',\n",
       "       'out_regdisaster', 'oilpop', 'zero_res', 'logoilres', 'oilpop_public',\n",
       "       'logoilres_public', 'logoilres_full', 'valoilres', 'valoilres_public',\n",
       "       'logvaloilres', 'logvaloilres_public', 'logvaloilres_full',\n",
       "       'oilpop_impute', 'logoilres_impute', 'valoilres_impute',\n",
       "       'logvaloilres_impute', 'logvalprod', 'logvalprod_impute',\n",
       "       'discoveryaspoPC', 'zero_disc', 'logdiscoveryaspo', 'logvaldisc',\n",
       "       'logGDP_M', 'logpop_M', 'logpopdens', 'democracy', 'x_dem',\n",
       "       'logmilexgdpSIPRI', 'logmountain', 'logoutreg', 'dincidence2COW',\n",
       "       'dmilexpSIPRI', 'dincidenceU', 'dcoup', 'decade', 'wildcatsample',\n",
       "       'lowincsample', 'opec', 'popdens_diff', 'pop_maddison_diff',\n",
       "       'democracy_diff', 'wildcat_diff', 'out_regdisaster_diff',\n",
       "       'valoilres_diff', 'valoilres_binarize', 'valoilres_public_diff',\n",
       "       'valoilres_public_binarize', 'oilpop_diff', 'oilpop_binarize',\n",
       "       'valoilres_impute_diff', 'valoilres_impute_binarize',\n",
       "       'oilpop_impute_diff', 'oilpop_impute_binarize',\n",
       "       'milexp_pergdpSIPRI_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oil_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b0d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT and ATE AIPTW\n",
    "def att_aiptw(Q0, Q1, g, A, Y, prob_t=None):\n",
    "    \"\"\"\n",
    "    Double ML estimator for the ATT\n",
    "    This uses the ATT specific scores, see equation 3.9 of https://www.econstor.eu/bitstream/10419/149795/1/869216953.pdf\n",
    "    Return: aiptw of ATE and its standard error\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of observations\n",
    "    n = Y.shape[0]\n",
    "    \n",
    "    # estimate marginal probability of treatment\n",
    "    if prob_t is None:\n",
    "        prob_t = A.mean() \n",
    "    \n",
    "    # att aiptw\n",
    "    tau_hat = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0)).mean()/ prob_t\n",
    "  \n",
    "    # influence curve and standard error of aiptw\n",
    "    phi = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0) - tau_hat*A) / prob_t\n",
    "    std_hat = np.std(phi) / np.sqrt(n)\n",
    "\n",
    "    return tau_hat, std_hat\n",
    "\n",
    "def ate_aiptw(Q0, Q1, g, A, Y, prob_t=None):\n",
    "    \"\"\"\n",
    "    Double ML estimator for the ATE\n",
    "    Return: aiptw of ATE and its standard error\n",
    "    \"\"\"\n",
    "    # number of observations\n",
    "    n = Y.shape[0]\n",
    "    \n",
    "    # ate aiptw\n",
    "    tau_hat = (Q1 - Q0 + A*(Y-Q1)/g - (1-A)*(Y-Q0)/(1-g)).mean()\n",
    "  \n",
    "    # influence curve and standard error of aiptw\n",
    "    phi = Q1 - Q0 + A*(Y-Q1)/g - (1-A)*(Y-Q0)/(1-g) - tau_hat   \n",
    "    std_hat = np.std(phi) / np.sqrt(n)\n",
    "\n",
    "    return tau_hat, std_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0be19d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional outcome models (Q models)\n",
    "def make_linear_Q_model():\n",
    "    ''' A function that returns a linear q model for later use in k-folding'''\n",
    "    return LinearRegression()\n",
    "\n",
    "def make_Q_model(output_type:str):\n",
    "    ''' A function that returns a general ML q model for later use in k-folding'''\n",
    "    if output_type == 'binary':\n",
    "        return RandomForestClassifier(random_state=RANDOM_SEED, n_estimators=500, max_depth=None)\n",
    "    return RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=500, max_depth=None)\n",
    "# One example: RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=500, max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cf517f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propensity score models (g models)\n",
    "def make_g_model():\n",
    "    ''' A function that returns a g model for computing propensity scores'''\n",
    "    return RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "# One example: RandomForestClassifier(n_estimators=100, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c52dee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for K-fold cross-fitting\n",
    "def treatment_k_fold_fit_and_predict(make_model, X:pd.DataFrame, A:np.array, n_splits:int):\n",
    "    '''\n",
    "    Implements K fold cross-fitting for the model predicting the treatment A. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns an array containing the predictions  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (which implements fit and predict_prob)\n",
    "    X: dataframe of variables to adjust for\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    '''\n",
    "\n",
    "    predictions = np.full_like(A, np.nan, dtype=float)\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, A):\n",
    "        X_train = X.loc[train_index]\n",
    "        A_train = A.loc[train_index]\n",
    "        g = make_model()\n",
    "        g.fit(X_train, A_train)\n",
    "\n",
    "        # get predictions for split\n",
    "        predictions[test_index] = g.predict_proba(X.loc[test_index])[:, 1]\n",
    "    \n",
    "    # sanity check that overlap holds\n",
    "    assert np.isnan(predictions).sum() == 0\n",
    "    return predictions\n",
    "\n",
    "def outcome_k_fold_fit_and_predict(make_model, X:pd.DataFrame, y:np.array, A:np.array, n_splits:int, output_type:str):\n",
    "    '''\n",
    "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
    "    X: dataframe of variables to adjust for\n",
    "    y: array of outcomes\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    output_type: type of outcome, \"binary\" or \"continuous\"\n",
    "    '''\n",
    "\n",
    "    predictions0 = np.full_like(A, np.nan, dtype=float)\n",
    "    predictions1 = np.full_like(y, np.nan, dtype=float)\n",
    "    if output_type == 'binary':\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    elif output_type == 'continuous':\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # include the treatment as input feature\n",
    "    X_w_treatment = X.copy()\n",
    "    X_w_treatment[\"A\"] = A\n",
    "\n",
    "    # for predicting effect under treatment / control status for each data point \n",
    "    X0 = X_w_treatment.copy()\n",
    "    X0[\"A\"] = 0\n",
    "    X1 = X_w_treatment.copy()\n",
    "    X1[\"A\"] = 1\n",
    "\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_w_treatment, y):\n",
    "        X_train = X_w_treatment.loc[train_index]\n",
    "        y_train = y.loc[train_index]\n",
    "        q = make_model(output_type)\n",
    "        q.fit(X_train, y_train)\n",
    "\n",
    "        if output_type =='binary':\n",
    "            predictions0[test_index] = q.predict_proba(X0.loc[test_index])[:, 1]\n",
    "            predictions1[test_index] = q.predict_proba(X1.loc[test_index])[:, 1]\n",
    "        elif output_type == 'continuous':\n",
    "            predictions0[test_index] = q.predict(X0.loc[test_index])\n",
    "            predictions1[test_index] = q.predict(X1.loc[test_index])\n",
    "\n",
    "    assert np.isnan(predictions0).sum() == 0\n",
    "    assert np.isnan(predictions1).sum() == 0\n",
    "    return predictions0, predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "120e881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vars = ['onset2COWCS',\n",
    "              'valoilres_binarize',\n",
    "              'ecgrowth',\n",
    "              'pop_maddison_diff',\n",
    "              'popdens_diff',\n",
    "              'democracy_diff',\n",
    "              'logmountain',\n",
    "              'ethnic_fractionalization',\n",
    "              'religion_fractionalization',\n",
    "              'language_fractionalization',\n",
    "              'leg_british',\n",
    "              'numcode',\n",
    "              'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f9a4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'onset2COWCS'\n",
    "treatment = 'valoilres_binarize'\n",
    "confounders = [x for x in model_vars if x not in (outcome + treatment)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "129b3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_run_model(df, outcome:str, treatment:str, confounders:list, make_g_model,\n",
    "                      make_Q_model, n_splits=5, output_type='binary', ate=True):\n",
    "    '''\n",
    "    Function that creates a g, q, and aiptw model based on the \n",
    "    given inputs\n",
    "    \n",
    "    Inputs: df (pandas df) - the dataframe the variables are contained in\n",
    "            outcome (str) - the outcome variable\n",
    "            treatment (str) - the treatment variable\n",
    "            confounders (lst) - a list of the confounding variables\n",
    "            make_g_model - the make_g_model function\n",
    "            make_Q_model - the make_Q_model function\n",
    "            n_splits (int) - number of splits for the model\n",
    "            output_type (str) - the desired output type, either binary or continous\n",
    "            ate (bool) - whether to use ate or alternative att\n",
    "    \n",
    "    Returns: tau_hat - the tau hat estimator for the average treatment effect\n",
    "             std of tau_hat - the standard deviation for the tau_hat estimator\n",
    "    '''\n",
    "    df = df.replace({outcome: .00001}, 0)\n",
    "    df = df[[outcome] + confounders + [treatment]]\n",
    "    df = df.dropna().reset_index()\n",
    "    print('Running models for treatment {} and outcome {} on {} samples'.format(treatment, outcome, len(df)))\n",
    "    outcome = df[outcome]\n",
    "    confounders = df[confounders]\n",
    "    treatment = df[treatment]\n",
    "    \n",
    "    g = treatment_k_fold_fit_and_predict(make_g_model, X=confounders, A=treatment, n_splits=n_splits)\n",
    "    \n",
    "    if min(g) < .01:\n",
    "        print('\\nWARNING:\\n Some propensity scores are very small,\\n which could '\n",
    "              'lead to an inflated AIPTW.\\n Minimum score = ', min(g))\n",
    "    if max(g) > .99:\n",
    "        print('\\nWARNING:\\n Some propensity scores are very large,\\n which could '\n",
    "              'lead to an inflated AIPTW.\\n Maximum score = ', max(g))\n",
    "    print('G Model has been fit')\n",
    "\n",
    "    Q0_ml, Q1_ml = outcome_k_fold_fit_and_predict(make_Q_model, X=confounders, y=outcome, A=treatment, \\\n",
    "                                                  n_splits=n_splits, output_type=output_type)\n",
    "    \n",
    "    print('Q model has been fit')\n",
    "    data_and_nuisance_estimates_ml = pd.DataFrame({'g': g, 'Q0': Q0_ml, 'Q1': Q1_ml, 'A': treatment, 'Y': outcome})\n",
    "    \n",
    "    # ate aiptw\n",
    "    if ate:\n",
    "        tau_hat, std_hat = ate_aiptw(**data_and_nuisance_estimates_ml)\n",
    "    else: \n",
    "        tau_hat, std_hat = att_aiptw(**data_and_nuisance_estimates_ml)\n",
    "    print('AIPTW model has been fit. Returning \\u03C4 hat and its standard deviation')\n",
    "    print('\\u03C4 hat = {} and std = {}\\n'.format(round(tau_hat, 5), round(std_hat, 5)))\n",
    "    return tau_hat, std_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b70b43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_lst = ['valoilres_binarize', # value of oil reserves\n",
    "               'valoilres_public_binarize', # value of oil reserves from public data\n",
    "               'oilpop_binarize', # oil reserves per capita in million barrels per 1000 persons\n",
    "               'valoilres_impute_binarize', # value of oilpop_impute (multiply by crude oil price)\n",
    "               'oilpop_impute_binarize']\n",
    "\n",
    "outcome_lst = ['onset2COWCS',\n",
    "               'onsetUCS',\n",
    "               'coup',\n",
    "               'periregular',\n",
    "               'milexp_pergdpSIPRI_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d3216025",
   "metadata": {},
   "outputs": [],
   "source": [
    "undemocratic_countries_df = oil_df[oil_df['democracy'] <= oil_df['democracy'].median()]\n",
    "democratic_countries_df = oil_df[oil_df['democracy'] > oil_df['democracy'].median()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ecfa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running models for treatment valoilres_binarize and outcome onset2COWCS on 5174 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = 0.00409 and std = 0.00451\n",
      "\n",
      "Running models for treatment valoilres_binarize and outcome onsetUCS on 4754 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = 0.00998 and std = 0.00776\n",
      "\n",
      "Running models for treatment valoilres_binarize and outcome coup on 5364 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = -0.00383 and std = 0.01143\n",
      "\n",
      "Running models for treatment valoilres_binarize and outcome periregular on 3312 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = -0.01315 and std = 0.00487\n",
      "\n",
      "Running models for treatment valoilres_binarize and outcome milexp_pergdpSIPRI_diff on 1302 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = 0.41313 and std = 0.32466\n",
      "\n",
      "Running models for treatment valoilres_public_binarize and outcome onset2COWCS on 4751 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = 0.00232 and std = 0.00429\n",
      "\n",
      "Running models for treatment valoilres_public_binarize and outcome onsetUCS on 4715 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = 0.0176 and std = 0.00666\n",
      "\n",
      "Running models for treatment valoilres_public_binarize and outcome coup on 5504 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = 0.02325 and std = 0.01132\n",
      "\n",
      "Running models for treatment valoilres_public_binarize and outcome periregular on 2582 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = -0.00872 and std = 0.00634\n",
      "\n",
      "Running models for treatment valoilres_public_binarize and outcome milexp_pergdpSIPRI_diff on 1532 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = 0.38067 and std = 0.29284\n",
      "\n",
      "Running models for treatment oilpop_binarize and outcome onset2COWCS on 5174 samples\n",
      "\n",
      "WARNING:\n",
      " Some propensity scores are very small,\n",
      " which could lead to an inflated AIPTW.\n",
      " Minimum score =  0.0035885756334921603\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = -0.0031 and std = 0.00419\n",
      "\n",
      "Running models for treatment oilpop_binarize and outcome onsetUCS on 4754 samples\n",
      "\n",
      "WARNING:\n",
      " Some propensity scores are very small,\n",
      " which could lead to an inflated AIPTW.\n",
      " Minimum score =  0.0026634629588569415\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = -0.00062 and std = 0.00823\n",
      "\n",
      "Running models for treatment oilpop_binarize and outcome coup on 5364 samples\n",
      "\n",
      "WARNING:\n",
      " Some propensity scores are very small,\n",
      " which could lead to an inflated AIPTW.\n",
      " Minimum score =  0.0042740641878669956\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = 0.02519 and std = 0.02837\n",
      "\n",
      "Running models for treatment oilpop_binarize and outcome periregular on 3312 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard deviation\n",
      "τ hat = -0.00519 and std = 0.00472\n",
      "\n",
      "Running models for treatment oilpop_binarize and outcome milexp_pergdpSIPRI_diff on 1302 samples\n",
      "\n",
      "WARNING:\n",
      " Some propensity scores are very small,\n",
      " which could lead to an inflated AIPTW.\n",
      " Minimum score =  0.00015995346683879988\n",
      "G Model has been fit\n"
     ]
    }
   ],
   "source": [
    "for treat in treatment_lst:\n",
    "    for out in outcome_lst:\n",
    "        if len(oil_df[out].value_counts()) == 2:\n",
    "            output = 'binary'\n",
    "        else:\n",
    "            output = 'continuous'\n",
    "        fit_and_run_model(oil_df, out, treat, confounders, make_g_model, make_Q_model, output_type=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e648e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for treat in treatment_lst:\n",
    "    for out in outcome_lst:\n",
    "        if len(oil_df[out].value_counts()) == 2:\n",
    "            output = 'binary'\n",
    "        else:\n",
    "            output = 'continuous'\n",
    "        fit_and_run_model(oil_df, out, treat, confounders, make_g_model, make_Q_model, output_type=output, ate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
