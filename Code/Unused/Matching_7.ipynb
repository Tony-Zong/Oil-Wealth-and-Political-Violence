{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98cb23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import sklearn\n",
    "import os\n",
    "from matplotlib.pyplot import hist\n",
    "from psmpy import PsmPy\n",
    "from psmpy.functions import cohenD\n",
    "from psmpy.plotting import *\n",
    "# import more functions or modules if you need them !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdbd3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for numpy\n",
    "RANDOM_SEED=42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1208739a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80f52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT and ATE AIPTW\n",
    "def att_aiptw(Q0, Q1, g, A, Y, prob_t=None):\n",
    "    \"\"\"\n",
    "    Double ML estimator for the ATT\n",
    "    This uses the ATT specific scores, see equation 3.9 of https://www.econstor.eu/bitstream/10419/149795/1/869216953.pdf\n",
    "    Return: aiptw of ATE and its standard error\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of observations\n",
    "    n = Y.shape[0]\n",
    "    \n",
    "    # estimate marginal probability of treatment\n",
    "    if prob_t is None:\n",
    "        prob_t = A.mean() \n",
    "    \n",
    "    # att aiptw\n",
    "    tau_hat = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0)).mean()/ prob_t\n",
    "  \n",
    "    # influence curve and standard error of aiptw\n",
    "    phi = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0) - tau_hat*A) / prob_t\n",
    "    std_hat = np.std(phi) / np.sqrt(n)\n",
    "\n",
    "    return tau_hat, std_hat\n",
    "\n",
    "def ate_aiptw(Q0, Q1, g, A, Y, prob_t=None):\n",
    "    \"\"\"\n",
    "    Double ML estimator for the ATE\n",
    "    Return: aiptw of ATE and its standard error\n",
    "    \"\"\"\n",
    "    # number of observations\n",
    "    n = Y.shape[0]\n",
    "    \n",
    "    # ate aiptw\n",
    "    tau_hat = (Q1 - Q0 + A*(Y-Q1)/g - (1-A)*(Y-Q0)/(1-g)).mean()\n",
    "  \n",
    "    # influence curve and standard error of aiptw\n",
    "    phi = Q1 - Q0 + A*(Y-Q1)/g - (1-A)*(Y-Q0)/(1-g) - tau_hat   \n",
    "    std_hat = np.std(phi) / np.sqrt(n)\n",
    "\n",
    "    return tau_hat, std_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2231d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional outcome models (Q models)\n",
    "def make_linear_Q_model():\n",
    "    ''' A function that returns a linear q model for later use in k-folding'''\n",
    "    return LinearRegression()\n",
    "\n",
    "def make_Q_model(output_type:str):\n",
    "    ''' A function that returns a general ML q model for later use in k-folding'''\n",
    "    if output_type == 'binary':\n",
    "        return RandomForestClassifier(random_state=RANDOM_SEED, n_estimators=500, max_depth=None)\n",
    "    return RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=500, max_depth=None)\n",
    "# One example: RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=500, max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0ebfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propensity score models (g models)\n",
    "def make_g_model():\n",
    "    ''' A function that returns a g model for computing propensity scores'''\n",
    "    return RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "# One example: RandomForestClassifier(n_estimators=100, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc2c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for K-fold cross-fitting\n",
    "def treatment_k_fold_fit_and_predict(make_model, X:pd.DataFrame, A:np.array, n_splits:int):\n",
    "    '''\n",
    "    Implements K fold cross-fitting for the model predicting the treatment A. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns an array containing the predictions  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (which implements fit and predict_prob)\n",
    "    X: dataframe of variables to adjust for\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    '''\n",
    "\n",
    "    predictions = np.full_like(A, np.nan, dtype=float)\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, A):\n",
    "        X_train = X.loc[train_index]\n",
    "        A_train = A.loc[train_index]\n",
    "        g = make_model()\n",
    "        g.fit(X_train, A_train)\n",
    "\n",
    "        # get predictions for split\n",
    "        predictions[test_index] = g.predict_proba(X.loc[test_index])[:, 1]\n",
    "    \n",
    "    # sanity check that overlap holds\n",
    "    assert np.isnan(predictions).sum() == 0\n",
    "    return predictions\n",
    "\n",
    "def outcome_k_fold_fit_and_predict(make_model, X:pd.DataFrame, y:np.array, A:np.array, n_splits:int, output_type:str):\n",
    "    '''\n",
    "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
    "    X: dataframe of variables to adjust for\n",
    "    y: array of outcomes\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    output_type: type of outcome, \"binary\" or \"continuous\"\n",
    "    '''\n",
    "\n",
    "    predictions0 = np.full_like(A, np.nan, dtype=float)\n",
    "    predictions1 = np.full_like(y, np.nan, dtype=float)\n",
    "    if output_type == 'binary':\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    elif output_type == 'continuous':\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # include the treatment as input feature\n",
    "    X_w_treatment = X.copy()\n",
    "    X_w_treatment[\"A\"] = A\n",
    "\n",
    "    # for predicting effect under treatment / control status for each data point \n",
    "    X0 = X_w_treatment.copy()\n",
    "    X0[\"A\"] = 0\n",
    "    X1 = X_w_treatment.copy()\n",
    "    X1[\"A\"] = 1\n",
    "\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_w_treatment, y):\n",
    "        X_train = X_w_treatment.loc[train_index]\n",
    "        y_train = y.loc[train_index]\n",
    "        q = make_model(output_type)\n",
    "        q.fit(X_train, y_train)\n",
    "\n",
    "        if output_type =='binary':\n",
    "            predictions0[test_index] = q.predict_proba(X0.loc[test_index])[:, 1]\n",
    "            predictions1[test_index] = q.predict_proba(X1.loc[test_index])[:, 1]\n",
    "        elif output_type == 'continuous':\n",
    "            predictions0[test_index] = q.predict(X0.loc[test_index])\n",
    "            predictions1[test_index] = q.predict(X1.loc[test_index])\n",
    "\n",
    "    assert np.isnan(predictions0).sum() == 0\n",
    "    assert np.isnan(predictions1).sum() == 0\n",
    "    return predictions0, predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "239b2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_run_model(df, outcome:str, treatment:str, confounders:list, make_g_model,\n",
    "                      make_Q_model, n_splits=5, output_type='binary', ate=True):\n",
    "    '''\n",
    "    Function that creates a g, q, and aiptw model based on the \n",
    "    given inputs\n",
    "    \n",
    "    Inputs: df (pandas df) - the dataframe the variables are contained in\n",
    "            outcome (str) - the outcome variable\n",
    "            treatment (str) - the treatment variable\n",
    "            confounders (lst) - a list of the confounding variables\n",
    "            make_g_model - the make_g_model function\n",
    "            make_Q_model - the make_Q_model function\n",
    "            n_splits (int) - number of splits for the model\n",
    "            output_type (str) - the desired output type, either binary or continous\n",
    "            ate (bool) - whether to use ate or alternative att\n",
    "    \n",
    "    Returns: tau_hat - the tau hat estimator for the average treatment effect\n",
    "             std of tau_hat - the standard deviation for the tau_hat estimator\n",
    "    '''\n",
    "    df = df.replace({outcome: .00001}, 0)\n",
    "    df = df[[outcome] + confounders + [treatment]]\n",
    "    df = df.dropna().reset_index()\n",
    "    print('Running models for treatment {} and outcome {} on {} samples'.format(treatment, outcome, len(df)))\n",
    "    outcome = df[outcome]\n",
    "    confounders = df[confounders]\n",
    "    treatment = df[treatment]\n",
    "    \n",
    "    g = treatment_k_fold_fit_and_predict(make_g_model, X=confounders, A=treatment, n_splits=n_splits)\n",
    "    \n",
    "    if min(g) < .01:\n",
    "        print('\\nWARNING:\\n Some propensity scores are very small,\\n which could '\n",
    "              'lead to an inflated AIPTW.\\n Minimum score = ', min(g))\n",
    "    if max(g) > .99:\n",
    "        print('\\nWARNING:\\n Some propensity scores are very large,\\n which could '\n",
    "              'lead to an inflated AIPTW.\\n Maximum score = ', max(g))\n",
    "    print('G Model has been fit')\n",
    "\n",
    "    Q0_ml, Q1_ml = outcome_k_fold_fit_and_predict(make_Q_model, X=confounders, y=outcome, A=treatment, \\\n",
    "                                                  n_splits=n_splits, output_type=output_type)\n",
    "    \n",
    "    print('Q model has been fit')\n",
    "    data_and_nuisance_estimates_ml = pd.DataFrame({'g': g, 'Q0': Q0_ml, 'Q1': Q1_ml, 'A': treatment, 'Y': outcome})\n",
    "    \n",
    "    # ate aiptw\n",
    "    if ate:\n",
    "        tau_hat, std_hat = ate_aiptw(**data_and_nuisance_estimates_ml)\n",
    "    else: \n",
    "        tau_hat, std_hat = att_aiptw(**data_and_nuisance_estimates_ml)\n",
    "    print('AIPTW model has been fit. Returning \\u03C4 hat and its standard deviation')\n",
    "    print('\\u03C4 hat = {} and std = {}\\n'.format(round(tau_hat, 5), round(std_hat, 5)))\n",
    "    return tau_hat, std_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cf75ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata('/Users/zwanran/Desktop/STAT27420/Final/STAT27420-final-code/Data/data/aspo_full_matching.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91b89914",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vars = ['onset2COWCS',\n",
    "              'success',\n",
    "              'wildcat_diff',\n",
    "              'wildcat_diff_binary',\n",
    "              'valoilres_diff',\n",
    "              'ecgrowth', \n",
    "              'popdens_diff', \n",
    "              'democracy_diff', \n",
    "              'numcode',\n",
    "              'logmountain',\n",
    "              'incidence2COW',\n",
    "              'africa',\n",
    "              'southam',\n",
    "              'asia',\n",
    "              'oceania',\n",
    "              'year']\n",
    "df = df[model_vars]\n",
    "df = df.dropna()\n",
    "df['index'] = np.arange(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e5ddf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>valoilres_diff</th>\n",
       "      <th>ecgrowth</th>\n",
       "      <th>popdens_diff</th>\n",
       "      <th>democracy_diff</th>\n",
       "      <th>logmountain</th>\n",
       "      <th>incidence2COW</th>\n",
       "      <th>africa</th>\n",
       "      <th>southam</th>\n",
       "      <th>asia</th>\n",
       "      <th>oceania</th>\n",
       "      <th>propensity_score</th>\n",
       "      <th>propensity_logit</th>\n",
       "      <th>wildcat_diff_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.001408</td>\n",
       "      <td>0.038898</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027537</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.479142</td>\n",
       "      <td>-0.083482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.034214</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027537</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.477765</td>\n",
       "      <td>-0.089000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.056571</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.482472</td>\n",
       "      <td>-0.070141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.120336</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.509772</td>\n",
       "      <td>0.039091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>-0.001942</td>\n",
       "      <td>0.093678</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032426</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.470816</td>\n",
       "      <td>-0.116871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>2740</td>\n",
       "      <td>-0.001936</td>\n",
       "      <td>0.046573</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033032</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.368021</td>\n",
       "      <td>-0.540715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>2741</td>\n",
       "      <td>-0.005182</td>\n",
       "      <td>0.015156</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033032</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.358615</td>\n",
       "      <td>-0.581383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>2742</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033032</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.356072</td>\n",
       "      <td>-0.592452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>2744</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033032</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.355495</td>\n",
       "      <td>-0.594971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>2746</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033032</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.355379</td>\n",
       "      <td>-0.595476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2747 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  valoilres_diff  ecgrowth  popdens_diff  democracy_diff  \\\n",
       "0        11       -0.001408  0.038898      0.000306        0.000000   \n",
       "1        12       -0.000054  0.034214      0.000302        0.000000   \n",
       "2        33        0.002051  0.056571      0.000210       -0.125000   \n",
       "3        35        0.000188  0.120336      0.000208        0.142857   \n",
       "4        43       -0.001942  0.093678      0.000049        0.000000   \n",
       "...     ...             ...       ...           ...             ...   \n",
       "2742   2740       -0.001936  0.046573      0.000322        0.000000   \n",
       "2743   2741       -0.005182  0.015156      0.000328        0.000000   \n",
       "2744   2742        0.002095  0.004042      0.000333        0.000000   \n",
       "2745   2744       -0.002969  0.003624      0.000337        0.000000   \n",
       "2746   2746        0.000133  0.002246      0.000341        0.000000   \n",
       "\n",
       "      logmountain  incidence2COW   africa  southam     asia  oceania  \\\n",
       "0        0.027537        0.00001  1.00000  0.00001  0.00001  0.00001   \n",
       "1        0.027537        0.00001  1.00000  0.00001  0.00001  0.00001   \n",
       "2        0.022721        0.00001  1.00000  0.00001  0.00001  0.00001   \n",
       "3        0.022721        0.00001  1.00000  0.00001  0.00001  0.00001   \n",
       "4        0.032426        0.00001  0.00001  0.00001  1.00000  0.00001   \n",
       "...           ...            ...      ...      ...      ...      ...   \n",
       "2742     0.033032        0.00001  0.00001  0.00001  1.00000  0.00001   \n",
       "2743     0.033032        0.00001  0.00001  0.00001  1.00000  0.00001   \n",
       "2744     0.033032        0.00001  0.00001  0.00001  1.00000  0.00001   \n",
       "2745     0.033032        0.00001  0.00001  0.00001  1.00000  0.00001   \n",
       "2746     0.033032        0.00001  0.00001  0.00001  1.00000  0.00001   \n",
       "\n",
       "      propensity_score  propensity_logit  wildcat_diff_binary  \n",
       "0             0.479142         -0.083482                    1  \n",
       "1             0.477765         -0.089000                    1  \n",
       "2             0.482472         -0.070141                    1  \n",
       "3             0.509772          0.039091                    1  \n",
       "4             0.470816         -0.116871                    1  \n",
       "...                ...               ...                  ...  \n",
       "2742          0.368021         -0.540715                    0  \n",
       "2743          0.358615         -0.581383                    0  \n",
       "2744          0.356072         -0.592452                    0  \n",
       "2745          0.355495         -0.594971                    0  \n",
       "2746          0.355379         -0.595476                    0  \n",
       "\n",
       "[2747 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psm = PsmPy(df, treatment='wildcat_diff_binary', indx='index', exclude = ['year', 'numcode', 'success', 'wildcat_diff', 'onset2COWCS'])\n",
    "psm.logistic_ps(balance = True)\n",
    "psm.predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4824e033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zwanran/opt/anaconda3/lib/python3.9/site-packages/psmpy/psmpy.py:346: UserWarning: Some values do not have a match\n",
      "  warnings.warn('Some values do not have a match')\n"
     ]
    }
   ],
   "source": [
    "psm.knn_matched(matcher='propensity_logit', replacement=False, caliper=None)\n",
    "# version 2:\n",
    "# psm.knn_matched_12n(matcher='propensity_logit', how_many=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_lst = ['wildcat_diff']\n",
    "outcome_lst = ['onset2COWCS']\n",
    "confounders = [x for x in model_vars if x not in (outcome + treatment)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc446c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'model': [], 'treatment': [], 'outcome': [], 'tau_hat': [], 'tau_std': []}\n",
    "for treat in treatment_lst:\n",
    "    for out in outcome_lst:\n",
    "        if len(oil_df[out].value_counts()) == 2:\n",
    "            output = 'binary'\n",
    "        else:\n",
    "            output = 'continuous'\n",
    "        tau_hat, tau_std = fit_and_run_model(oil_df, out, treat, confounders, make_g_model, make_Q_model, output_type=output)\n",
    "        df_dict['model'].append('ate')\n",
    "        df_dict['treatment'].append(treat)\n",
    "        df_dict['outcome'].append(out)\n",
    "        df_dict['tau_hat'].append(tau_hat)\n",
    "        df_dict['tau_std'].append(tau_std)\n",
    "\n",
    "ate_results_df = pd.DataFrame(data=df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'model': [], 'treatment': [], 'outcome': [], 'tau_hat': [], 'tau_std': []}\n",
    "for treat in treatment_lst:\n",
    "    for out in outcome_lst:\n",
    "        if len(oil_df[out].value_counts()) == 2:\n",
    "            output = 'binary'\n",
    "        else:\n",
    "            output = 'continuous'\n",
    "        tau_hat, tau_std = fit_and_run_model(oil_df, out, treat, confounders, make_g_model, make_Q_model, output_type=output, ate=False)\n",
    "        df_dict['model'].append('att')\n",
    "        df_dict['treatment'].append(treat)\n",
    "        df_dict['outcome'].append(out)\n",
    "        df_dict['tau_hat'].append(tau_hat)\n",
    "        df_dict['tau_std'].append(tau_std)\n",
    "\n",
    "att_results_df = pd.DataFrame(data=df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad94994",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([ate_results_df, att_results_df])\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
